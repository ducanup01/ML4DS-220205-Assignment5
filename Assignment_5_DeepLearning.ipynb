{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6DyphAUEBOi"
      },
      "source": [
        "# Assignment 5: Deep Learning {-}\n",
        "\n",
        "This assignment aims at familiarizing you with training and testing a Deep Neural Network (DNN). The dataset you will be working on is CIFAR-10. You will have to do:\n",
        "\n",
        "1.  **(5 points) Coding tasks:** The following questions involve writing code to complete specific tasks.  \n",
        "    1.1 *(1 point)* Load the CIFAR-10 dataset, visualize sample images, and perform data normalization to improve training performance.  \n",
        "    1.2 *(1 point)* First network: Build, train, and test a deep neural network with at least three convolutional layers, two fully connected layers, and two pooling layers.  \n",
        "    1.3 *(1 point)* Second network: Build, train, and test another deep neural network, with an architecture of your choice, but at most 4M (four million) parameters, ensuring the architecture meets this constraint by verifying with model.summary().  \n",
        "    1.4 *(2 points)* Modify the second network architecture by tuning the layer hyperparameters or adjusting the layer design to improve test accuracy while remaining within the four million parameter limit. Discuss your observations and the trade offs of the changes you make.  \n",
        "\n",
        "2.  **(5 points) Open discussion questions:** These discussion questions ask you to analyze and argue your points.  Feel free to include relevant code examples to strengthen your arguments.  \n",
        "    2.1 *(1 point)* How did hyperparameter tuning (learning rate, dropout, batch size) affect your model’s accuracy? Were there any unexpected results?  \n",
        "    2.2 *(1 point)* How did the constraint of keeping the model within 4 million parameters impact your design choices? Would a larger model necessarily perform better?  \n",
        "    2.3 *(1 point)* How can deep learning models trained on datasets like CIFAR-10 be applied in real-world scenarios? Give an example.  \n",
        "    2.4 *(1 point)* Deep learning models for image recognition can have biases. What ethical concerns should be considered when deploying such models?  \n",
        "    2.5 *(1 point)* What was the most interesting or challenging part of this assignment? If you had more time, what additional improvements would you make?  \n",
        "\n",
        "The dataset you will be working on is CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html) which consists of 60,000 32x32 colour images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. Here follows the ten object classes:\n",
        "* airplane\n",
        "*\tautomobile\n",
        "*\tbird\n",
        "*\tcat\n",
        "*\tdeer\n",
        "*\tdog\n",
        "*\tfrog\n",
        "*\thorse\n",
        "*\tship\n",
        "*\ttruck\n",
        "\n",
        "Here follows some data samples in the dataset:\n",
        "\n",
        "![alt text](https://docs.pytorch.org/tutorials/_images/cifar10.png)\n",
        "\n",
        "### Submission {-}\n",
        "The structure of submission folder should be organized as follows:\n",
        "\n",
        "- ./\\<StudentID>-assignment5-notebook.ipynb: Jupyter notebook containing source code.\n",
        "- ./\\<Test-accuracy>-\\<StudentID>.txt: accuracy of the second network on the test set (for extra credit, see the 'Evaluation' part below). For example if you get 0.8124 accuracy, the name of this file is 08124-2012345.txt. The file content is left empty.\n",
        "\n",
        "The submission folder is named ML4DS-\\<StudentID>-Assignment5 (e.g., ML4DS-2012345-Assigment5) and then compressed with the same name.\n",
        "    \n",
        "### Evaluation {-}\n",
        "Assignment evaluation will be conducted on how you accomplish the assignment requirements. It is a plus if you have modeling steps other than the basic requirements and achieve an excellent model accuracy. In addition, your code should conform to a Python coding convention such as PEP-8.\n",
        "\n",
        "EXTRA CREDIT: Top-3 submissions achieving the highest test accuracy on the second network (of 4M params at most) will be rewarded an extra credit. **You have to ensure the architecture meets this constraint by verifying and printing out the number of parameters with model.summary(). Please follow the submission format to be eligible for this extra credit.**\n",
        "\n",
        "### Deadline {-}\n",
        "Please visit Canvas for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7yiMO-bEBOl"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras              # Keras is the high-level API of TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "XNiW7SuwTnbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6_ZhoDnfROl"
      },
      "outputs": [],
      "source": [
        "# PLEASE DO NOT CHANGE THIS CODE\n",
        "\n",
        "# Load the cifar10 dataset and split train/test\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Split train/valid from the training set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=5)\n",
        "\n",
        "print(\"Train shape: X_train = \" + str(X_train.shape) + \", y_train = \" + str(y_train.shape))\n",
        "print(\"Validation shape: X_val = \" + str(X_val.shape) + \", y_val = \" + str(y_val.shape))\n",
        "print(\"Test shape: X_test = \" + str(X_test.shape) + \", y_test = \" + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- TEMPORARILY reduce training set to 200 samples for quick testing -----\n",
        "X_train = X_train[:200]\n",
        "y_train = y_train[:200]\n",
        "\n",
        "print(\"Reduced Train shape: X_train = \" + str(X_train.shape) + \", y_train = \" + str(y_train.shape))\n"
      ],
      "metadata": {
        "id": "u8pzyZGUcy6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9EqVmHqfoL9"
      },
      "outputs": [],
      "source": [
        "# # Show some samples in the dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "# imgplot = plt.imshow(X_train[44999])\n",
        "# plt.show()\n",
        "# imgplot = plt.imshow(X_test[4999])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH7QNspP7U64"
      },
      "source": [
        "## 1. Coding tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMvWeE2K7U64"
      },
      "source": [
        "1. Load the CIFAR-10 dataset, visualize sample images, and perform data normalization to improve training performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBUR3PfK7U64"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# CIFAR-10 class names\n",
        "class_names = [\n",
        "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
        "]\n",
        "\n",
        "# Count how many samples belong to each class\n",
        "class_counts = np.bincount(y_train.flatten(), minlength=10)\n",
        "\n",
        "# For each class, collect indices of all images\n",
        "class_indices = {i: np.where(y_train.flatten() == i)[0] for i in range(10)}\n",
        "\n",
        "# Plot setup\n",
        "fig, axes = plt.subplots(4, 3, figsize=(6, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Randomly pick 4 images from this class\n",
        "    idxs = np.random.choice(class_indices[i], 4, replace=False)\n",
        "    imgs = X_train[idxs]\n",
        "\n",
        "    # Create a small 2x2 grid inside the subplot\n",
        "    combined = np.zeros((64, 64, 3), dtype=np.uint8)  # 32*2 = 64 pixels per side\n",
        "    combined[:32, :32] = imgs[0]\n",
        "    combined[:32, 32:] = imgs[1]\n",
        "    combined[32:, :32] = imgs[2]\n",
        "    combined[32:, 32:] = imgs[3]\n",
        "\n",
        "    ax.imshow(combined)\n",
        "    ax.set_title(f\"{class_names[i]} ({class_counts[i]})\", fontsize=10)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Turn off remaining unused subplots\n",
        "for ax in axes[10:]:\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lattfopb7U65"
      },
      "outputs": [],
      "source": [
        "# Convert pixel values from 0–255 to 0–1\n",
        "X_train_norm = X_train.astype(\"float32\") / 255.0\n",
        "X_val_norm = X_val.astype(\"float32\") / 255.0\n",
        "X_test_norm = X_test.astype(\"float32\") / 255.0\n",
        "\n",
        "print(\"Data normalized: pixel values are now between 0 and 1.\")\n",
        "print(\"Random normalized pixel: \", X_train_norm[44998][16][16])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPp7-Tum7U65"
      },
      "source": [
        "2. First network: Build, train, and test a deep neural network with at least three convolutional layers, two fully connected layers, and two pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgMj8cID7U65"
      },
      "outputs": [],
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# # First Convolution + Pooling\n",
        "# model.add(Conv2D(32, (5,5), activation='relu', input_shape=(X_train_norm.shape[1], X_train_norm.shape[2], X_train_norm.shape[3])))\n",
        "# model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "# # Second Convolution\n",
        "# model.add(Conv2D(64, (5,5), activation='relu'))\n",
        "\n",
        "\n",
        "# # Third Convolution + Pooling\n",
        "# model.add(Conv2D(128, (5,5), activation='relu'))\n",
        "# model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "# # Flatten before Dense layers\n",
        "# model.add(Flatten())\n",
        "\n",
        "# # Fully connected layers\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))  # Optional: helps prevent overfitting\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# # Output layer (change units based on number of classes)\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Summary of the model\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI1-azzN7U65"
      },
      "outputs": [],
      "source": [
        "# # Compile the model\n",
        "# model.compile(loss = tf.keras.losses.sparse_categorical_crossentropy, # Define loss function\n",
        "#                 optimizer= tf.keras.optimizers.Adam(learning_rate=1e-2), metrics=['accuracy']) # Define initial learning rate and metrics.\n",
        "\n",
        "\n",
        "# # Train the model. Using Colab for training\n",
        "# history = model.fit(X_train_norm, y_train, # Data feature and data label\n",
        "#                     batch_size=1024, # Batch size\n",
        "#                     epochs=10, # Number of training epochs\n",
        "#                     validation_data=(X_val_norm, y_val)) # Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktKgGGaO7U65"
      },
      "outputs": [],
      "source": [
        "# # Visualize training and validation performance\n",
        "# f,ax=plt.subplots(2,1)\n",
        "\n",
        "# # Plot training and validation loss\n",
        "# ax[0].plot(history.history['loss'], color='b',label='Training Loss')\n",
        "# ax[0].plot(history.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "# # Plot training and validation accuracy\n",
        "# ax[1].plot(history.history['accuracy'],color='b',label='Training Accuracy')\n",
        "# ax[1].plot(history.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "# plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RQM-Gea7U65"
      },
      "outputs": [],
      "source": [
        "# # Show the model performance\n",
        "# result = model.evaluate(X_test_norm, y_test) # If unspecified, batch_size will default to 32\n",
        "# print(model.metrics_names) # result[0] is loss, result[1] is accuracy. The metrics are defined in dnn_model.complie(...)\n",
        "# print(\"Loss and accuracy on the test set: loss = {}, accuracy = {}\".format(result[0],result[1]))\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHYK7nZG7U65"
      },
      "source": [
        "3. Second network: Build, train, and test another deep neural network, with an architecture of your choice, but at most 4M (four million) parameters, ensuring the architecture meets this constraint by verifying with model.summary()."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "VITiuZeKVyzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DINOv2 ViT-S/14\n",
        "dinov2 = torch.hub.load(\"facebookresearch/dinov2\", \"dinov2_vits14\")\n",
        "dinov2.eval()\n",
        "for p in dinov2.parameters():\n",
        "    p.requires_grad = False  # freeze backbone\n",
        "\n",
        "# Preprocessing for DINOv2\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, interpolation=3),    # Bicubic\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std =[0.229, 0.224, 0.225],\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "EHqKQcJxWSF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DinoDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.fromarray(self.X[idx])\n",
        "        x = transform(img).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            feat = dinov2(x).squeeze(0)  # shape (384,)\n",
        "\n",
        "        return feat, torch.tensor(self.y[idx][0], dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "TXz3OESqW2P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = DinoDataset(X_train, y_train)\n",
        "val_ds   = DinoDataset(X_val,   y_val)\n",
        "test_ds  = DinoDataset(X_test,  y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n"
      ],
      "metadata": {
        "id": "bcmA_KWZW3DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(384, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# Instantiate model\n",
        "model = Classifier().to(device)\n",
        "\n",
        "# Count parameters\n",
        "def count_params(model):\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return total, trainable\n",
        "\n",
        "total, trainable = count_params(model)\n",
        "print(f\"Classifier total parameters: {total:,}\")\n",
        "print(f\"Classifier trainable parameters: {trainable:,}\")\n",
        "\n",
        "# Loss & optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "r8miQejcXAs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_losses, val_losses = [], []\n",
        "# train_accs, val_accs = [], []\n",
        "\n",
        "# for epoch in range(10):\n",
        "#     model.train()\n",
        "#     total, correct, running_loss = 0, 0, 0\n",
        "\n",
        "#     for feats, labels in tqdm(train_loader):\n",
        "#         feats, labels = feats.to(device), labels.to(device)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(feats)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         running_loss += loss.item() * feats.size(0)\n",
        "#         _, predicted = outputs.max(1)\n",
        "#         correct += predicted.eq(labels).sum().item()\n",
        "#         total += labels.size(0)\n",
        "\n",
        "#     train_loss = running_loss / total\n",
        "#     train_acc  = correct / total\n",
        "#     train_losses.append(train_loss)\n",
        "#     train_accs.append(train_acc)\n",
        "\n",
        "#     # validation\n",
        "#     model.eval()\n",
        "#     total, correct, running_loss = 0, 0, 0\n",
        "#     with torch.no_grad():\n",
        "#         for feats, labels in val_loader:\n",
        "#             feats, labels = feats.to(device), labels.to(device)\n",
        "#             outputs = model(feats)\n",
        "#             loss = criterion(outputs, labels)\n",
        "\n",
        "#             running_loss += loss.item() * feats.size(0)\n",
        "#             _, predicted = outputs.max(1)\n",
        "#             correct += predicted.eq(labels).sum().item()\n",
        "#             total += labels.size(0)\n",
        "\n",
        "#     val_loss = running_loss / total\n",
        "#     val_acc  = correct / total\n",
        "#     val_losses.append(val_loss)\n",
        "#     val_accs.append(val_acc)\n",
        "\n",
        "#     print(f\"Epoch {epoch+1}/10 | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "_OkHbb0JXJbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training on precomputed features (fast) ---\n",
        "train_losses, val_losses = [], []\n",
        "train_accs, val_accs = [], []\n",
        "\n",
        "for epoch in range(1):  # change to range(10) for full training\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for feats, labels in tqdm(train_loader):\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(feats)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * feats.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = correct / total\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for feats, labels in val_loader:\n",
        "            feats, labels = feats.to(device), labels.to(device)\n",
        "            outputs = model(feats)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * feats.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_loss = running_loss / total\n",
        "    val_acc = correct / total\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/10 | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a6a608ac4a01463ea9bd0267d24686dd",
            "722088ec7bf2491eb11c8330f5739347",
            "31f1bdacb1674e3181e931cae861a6f4",
            "b225f6f389bd4073b8c66ec5ca4e8aac",
            "9e576b24e23344a29679c22e515fd975",
            "6196efa8425d4791975591e383206c56",
            "871857ecc6d94492a2acfb92440e2398",
            "569d163fdc8b4559b874f051d7c42e52",
            "fffc1186ce1c467389a80b5f46369b05",
            "970c3bea350549a4a32e01385c021391",
            "bc7c41e403bc46b486a45c0ffa5d626b"
          ]
        },
        "id": "8xmxhVhfbmaR",
        "outputId": "b4d1c3ca-0157-4210-bde6-c1cc480dd504"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6a608ac4a01463ea9bd0267d24686dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/704 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.title(\"Loss over epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_accs, label=\"Train Acc\")\n",
        "plt.plot(val_accs, label=\"Val Acc\")\n",
        "plt.title(\"Accuracy over epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5V15wPW9X7_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total, correct = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for feats, labels in test_loader:\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "        outputs = model(feats)\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_acc = correct / total\n",
        "print(\"Final Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "id": "ZJZcgUH1X-M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Save Model with Prefix 'dukemodel' ======\n",
        "import torch\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Create timestamp\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# File names\n",
        "weights_path = f\"dukemodel_{timestamp}.pth\"\n",
        "fullmodel_path = f\"dukemodel_{timestamp}_full.pth\"\n",
        "\n",
        "# Save weights only (recommended for PyTorch models)\n",
        "torch.save(model.state_dict(), weights_path)\n",
        "\n",
        "# Save full model (architecture + weights)\n",
        "torch.save(model, fullmodel_path)\n",
        "\n",
        "print(\"Model saved successfully:\")\n",
        "print(\"  Weights file :\", weights_path)\n",
        "print(\"  Full model   :\", fullmodel_path)\n",
        "print(\"\\nFiles are in:\", os.getcwd())\n"
      ],
      "metadata": {
        "id": "axyCafWlamly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVXGlx0o7U66"
      },
      "source": [
        "4. Modify the second network architecture by tuning the layer hyperparameters or adjusting the layer design to improve test accuracy while remaining within the four million parameter limit. Discuss your observations and the trade offs of the changes you make."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lE1pkmH7U66"
      },
      "outputs": [],
      "source": [
        "# Your code goes here. Please make sure to explain the reasons behind your data processing and modeling choices.\n",
        "# 1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYhcGpgT7U66"
      },
      "source": [
        "## 2. Open discussion questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhKcal8l7U66"
      },
      "source": [
        "1. How did hyperparameter tuning (learning rate, dropout, batch size) affect your model’s accuracy? Were there any unexpected results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5z2A3kI7U66"
      },
      "outputs": [],
      "source": [
        "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
        "# 2.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR-1QiBU7U66"
      },
      "source": [
        "2. How did the constraint of keeping the model within 4 million parameters impact your design choices? Would a larger model necessarily perform better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuiiZ4157U66"
      },
      "outputs": [],
      "source": [
        "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
        "# 2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr3nYv2_7U66"
      },
      "source": [
        "3. How can deep learning models trained on datasets like CIFAR-10 be applied in real-world scenarios? Give an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he9wMb2o7U66"
      },
      "outputs": [],
      "source": [
        "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
        "# 2.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NcTFag07U66"
      },
      "source": [
        "4. Deep learning models for image recognition can have biases. What ethical concerns should be considered when deploying such models?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGukYdCu7U66"
      },
      "outputs": [],
      "source": [
        "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
        "# 2.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xueUV-Vh7U66"
      },
      "source": [
        "5. What was the most interesting or challenging part of this assignment? If you had more time, what additional improvements would you make?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX_JXUJr7U66"
      },
      "outputs": [],
      "source": [
        "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
        "# 2.5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6a608ac4a01463ea9bd0267d24686dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_722088ec7bf2491eb11c8330f5739347",
              "IPY_MODEL_31f1bdacb1674e3181e931cae861a6f4",
              "IPY_MODEL_b225f6f389bd4073b8c66ec5ca4e8aac"
            ],
            "layout": "IPY_MODEL_9e576b24e23344a29679c22e515fd975"
          }
        },
        "722088ec7bf2491eb11c8330f5739347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6196efa8425d4791975591e383206c56",
            "placeholder": "​",
            "style": "IPY_MODEL_871857ecc6d94492a2acfb92440e2398",
            "value": "  4%"
          }
        },
        "31f1bdacb1674e3181e931cae861a6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_569d163fdc8b4559b874f051d7c42e52",
            "max": 704,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fffc1186ce1c467389a80b5f46369b05",
            "value": 29
          }
        },
        "b225f6f389bd4073b8c66ec5ca4e8aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_970c3bea350549a4a32e01385c021391",
            "placeholder": "​",
            "style": "IPY_MODEL_bc7c41e403bc46b486a45c0ffa5d626b",
            "value": " 29/704 [08:45&lt;3:19:38, 17.75s/it]"
          }
        },
        "9e576b24e23344a29679c22e515fd975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6196efa8425d4791975591e383206c56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871857ecc6d94492a2acfb92440e2398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "569d163fdc8b4559b874f051d7c42e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fffc1186ce1c467389a80b5f46369b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "970c3bea350549a4a32e01385c021391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7c41e403bc46b486a45c0ffa5d626b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}