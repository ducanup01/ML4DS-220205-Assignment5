{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec533c2",
   "metadata": {
    "id": "Y6DyphAUEBOi",
    "papermill": {
     "duration": 0.009694,
     "end_time": "2025-12-05T21:23:11.130483",
     "exception": false,
     "start_time": "2025-12-05T21:23:11.120789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Assignment 5: Deep Learning {-}\n",
    "\n",
    "This assignment aims at familiarizing you with training and testing a Deep Neural Network (DNN). The dataset you will be working on is CIFAR-10. You will have to do:\n",
    "\n",
    "1.  **(5 points) Coding tasks:** The following questions involve writing code to complete specific tasks.  \n",
    "    1.1 *(1 point)* Load the CIFAR-10 dataset, visualize sample images, and perform data normalization to improve training performance.  \n",
    "    1.2 *(1 point)* First network: Build, train, and test a deep neural network with at least three convolutional layers, two fully connected layers, and two pooling layers.  \n",
    "    1.3 *(1 point)* Second network: Build, train, and test another deep neural network, with an architecture of your choice, but at most 4M (four million) parameters, ensuring the architecture meets this constraint by verifying with model.summary().  \n",
    "    1.4 *(2 points)* Modify the second network architecture by tuning the layer hyperparameters or adjusting the layer design to improve test accuracy while remaining within the four million parameter limit. Discuss your observations and the trade offs of the changes you make.  \n",
    "\n",
    "2.  **(5 points) Open discussion questions:** These discussion questions ask you to analyze and argue your points.  Feel free to include relevant code examples to strengthen your arguments.  \n",
    "    2.1 *(1 point)* How did hyperparameter tuning (learning rate, dropout, batch size) affect your model’s accuracy? Were there any unexpected results?  \n",
    "    2.2 *(1 point)* How did the constraint of keeping the model within 4 million parameters impact your design choices? Would a larger model necessarily perform better?  \n",
    "    2.3 *(1 point)* How can deep learning models trained on datasets like CIFAR-10 be applied in real-world scenarios? Give an example.  \n",
    "    2.4 *(1 point)* Deep learning models for image recognition can have biases. What ethical concerns should be considered when deploying such models?  \n",
    "    2.5 *(1 point)* What was the most interesting or challenging part of this assignment? If you had more time, what additional improvements would you make?  \n",
    "\n",
    "The dataset you will be working on is CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html) which consists of 60,000 32x32 colour images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. Here follows the ten object classes:\n",
    "* airplane\n",
    "*\tautomobile\n",
    "*\tbird\n",
    "*\tcat\n",
    "*\tdeer\n",
    "*\tdog\n",
    "*\tfrog\n",
    "*\thorse\n",
    "*\tship\n",
    "*\ttruck\n",
    "\n",
    "Here follows some data samples in the dataset:\n",
    "\n",
    "![alt text](https://docs.pytorch.org/tutorials/_images/cifar10.png)\n",
    "\n",
    "### Submission {-}\n",
    "The structure of submission folder should be organized as follows:\n",
    "\n",
    "- ./\\<StudentID>-assignment5-notebook.ipynb: Jupyter notebook containing source code.\n",
    "- ./\\<Test-accuracy>-\\<StudentID>.txt: accuracy of the second network on the test set (for extra credit, see the 'Evaluation' part below). For example if you get 0.8124 accuracy, the name of this file is 08124-2012345.txt. The file content is left empty.\n",
    "\n",
    "The submission folder is named ML4DS-\\<StudentID>-Assignment5 (e.g., ML4DS-2012345-Assigment5) and then compressed with the same name.\n",
    "    \n",
    "### Evaluation {-}\n",
    "Assignment evaluation will be conducted on how you accomplish the assignment requirements. It is a plus if you have modeling steps other than the basic requirements and achieve an excellent model accuracy. In addition, your code should conform to a Python coding convention such as PEP-8.\n",
    "\n",
    "EXTRA CREDIT: Top-3 submissions achieving the highest test accuracy on the second network (of 4M params at most) will be rewarded an extra credit. **You have to ensure the architecture meets this constraint by verifying and printing out the number of parameters with model.summary(). Please follow the submission format to be eligible for this extra credit.**\n",
    "\n",
    "### Deadline {-}\n",
    "Please visit Canvas for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16818fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:23:11.151489Z",
     "iopub.status.busy": "2025-12-05T21:23:11.151038Z",
     "iopub.status.idle": "2025-12-05T21:23:18.513802Z",
     "shell.execute_reply": "2025-12-05T21:23:18.511173Z"
    },
    "id": "o7yiMO-bEBOl",
    "papermill": {
     "duration": 7.3768,
     "end_time": "2025-12-05T21:23:18.516248",
     "exception": false,
     "start_time": "2025-12-05T21:23:11.139448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras              # Keras is the high-level API of TensorFlow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae6779c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:23:18.550793Z",
     "iopub.status.busy": "2025-12-05T21:23:18.549488Z",
     "iopub.status.idle": "2025-12-05T21:23:18.678340Z",
     "shell.execute_reply": "2025-12-05T21:23:18.677391Z"
    },
    "papermill": {
     "duration": 0.144949,
     "end_time": "2025-12-05T21:23:18.679220",
     "exception": false,
     "start_time": "2025-12-05T21:23:18.534271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6e7aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:23:18.692741Z",
     "iopub.status.busy": "2025-12-05T21:23:18.692463Z",
     "iopub.status.idle": "2025-12-05T21:23:21.256018Z",
     "shell.execute_reply": "2025-12-05T21:23:21.254710Z"
    },
    "id": "M6_ZhoDnfROl",
    "papermill": {
     "duration": 2.574116,
     "end_time": "2025-12-05T21:23:21.259335",
     "exception": false,
     "start_time": "2025-12-05T21:23:18.685219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THIS CODE\n",
    "\n",
    "# Load the cifar10 dataset and split train/test\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Split train/valid from the training set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=5)\n",
    "\n",
    "y_train = y_train.reshape(-1,)\n",
    "y_val = y_val.reshape(-1,)\n",
    "y_test = y_test.reshape(-1,)\n",
    "\n",
    "\n",
    "print(\"Train shape: X_train = \" + str(X_train.shape) + \", y_train = \" + str(y_train.shape))\n",
    "print(\"Validation shape: X_val = \" + str(X_val.shape) + \", y_val = \" + str(y_val.shape))\n",
    "print(\"Test shape: X_test = \" + str(X_test.shape) + \", y_test = \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46193238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:23:21.284157Z",
     "iopub.status.busy": "2025-12-05T21:23:21.283834Z",
     "iopub.status.idle": "2025-12-05T21:23:21.508938Z",
     "shell.execute_reply": "2025-12-05T21:23:21.508125Z"
    },
    "id": "v9EqVmHqfoL9",
    "papermill": {
     "duration": 0.2386,
     "end_time": "2025-12-05T21:23:21.510598",
     "exception": false,
     "start_time": "2025-12-05T21:23:21.271998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show some samples in the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "imgplot = plt.imshow(X_train[44999])\n",
    "plt.show()\n",
    "imgplot = plt.imshow(X_test[4999])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398267cc",
   "metadata": {
    "id": "OH7QNspP7U64",
    "papermill": {
     "duration": 0.009588,
     "end_time": "2025-12-05T21:23:21.529954",
     "exception": false,
     "start_time": "2025-12-05T21:23:21.520366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Coding tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7d9ef",
   "metadata": {
    "id": "NMvWeE2K7U64",
    "papermill": {
     "duration": 0.009182,
     "end_time": "2025-12-05T21:23:21.548150",
     "exception": false,
     "start_time": "2025-12-05T21:23:21.538968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Load the CIFAR-10 dataset, visualize sample images, and perform data normalization to improve training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81daa13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:23:21.571097Z",
     "iopub.status.busy": "2025-12-05T21:23:21.570750Z",
     "iopub.status.idle": "2025-12-05T21:23:22.005937Z",
     "shell.execute_reply": "2025-12-05T21:23:22.004472Z"
    },
    "id": "oBUR3PfK7U64",
    "papermill": {
     "duration": 0.454353,
     "end_time": "2025-12-05T21:23:22.013290",
     "exception": false,
     "start_time": "2025-12-05T21:23:21.558937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "# Count how many samples belong to each class\n",
    "class_counts = np.bincount(y_train.flatten(), minlength=10)\n",
    "\n",
    "# For each class, collect indices of all images\n",
    "class_indices = {i: np.where(y_train.flatten() == i)[0] for i in range(10)}\n",
    "\n",
    "# Plot setup\n",
    "fig, axes = plt.subplots(4, 3, figsize=(6, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Randomly pick 4 images from this class\n",
    "    idxs = np.random.choice(class_indices[i], 4, replace=False)\n",
    "    imgs = X_train[idxs]\n",
    "\n",
    "    # Create a small 2x2 grid inside the subplot\n",
    "    combined = np.zeros((64, 64, 3), dtype=np.uint8)  # 32*2 = 64 pixels per side\n",
    "    combined[:32, :32] = imgs[0]\n",
    "    combined[:32, 32:] = imgs[1]\n",
    "    combined[32:, :32] = imgs[2]\n",
    "    combined[32:, 32:] = imgs[3]\n",
    "\n",
    "    ax.imshow(combined)\n",
    "    ax.set_title(f\"{class_names[i]} ({class_counts[i]})\", fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Turn off remaining unused subplots\n",
    "for ax in axes[10:]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2be59c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:23:22.055573Z",
     "iopub.status.busy": "2025-12-05T21:23:22.055175Z",
     "iopub.status.idle": "2025-12-05T21:23:22.784197Z",
     "shell.execute_reply": "2025-12-05T21:23:22.782338Z"
    },
    "id": "Lattfopb7U65",
    "papermill": {
     "duration": 0.751456,
     "end_time": "2025-12-05T21:23:22.785796",
     "exception": false,
     "start_time": "2025-12-05T21:23:22.034340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert pixel values from 0–255 to 0–1 (normalizing)\n",
    "X_train_norm = X_train.astype(\"float32\") / 255.0\n",
    "X_val_norm = X_val.astype(\"float32\") / 255.0\n",
    "X_test_norm = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "print(\"Data normalized: pixel values are now between 0 and 1.\")\n",
    "print(\"Random normalized pixel: \", X_train_norm[44998][16][16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20986b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training setup\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Training on:\", device)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_t = torch.tensor(X_train_norm, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "X_val_t   = torch.tensor(X_val_norm, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "X_test_t  = torch.tensor(X_test_norm, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "\n",
    "y_train_t = torch.tensor(y_train.reshape(-1), dtype=torch.long)\n",
    "y_val_t   = torch.tensor(y_val.reshape(-1), dtype=torch.long)\n",
    "y_test_t  = torch.tensor(y_test.reshape(-1), dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=128)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b2b8fa",
   "metadata": {
    "id": "uPp7-Tum7U65",
    "papermill": {
     "duration": 0.01362,
     "end_time": "2025-12-05T21:23:22.813736",
     "exception": false,
     "start_time": "2025-12-05T21:23:22.800116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. First network: Build, train, and test a deep neural network with at least three convolutional layers, two fully connected layers, and two pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b699c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:23:22.842943Z",
     "iopub.status.busy": "2025-12-05T21:23:22.842531Z",
     "iopub.status.idle": "2025-12-05T21:23:22.849795Z",
     "shell.execute_reply": "2025-12-05T21:23:22.848448Z"
    },
    "id": "xgMj8cID7U65",
    "papermill": {
     "duration": 0.023854,
     "end_time": "2025-12-05T21:23:22.850952",
     "exception": false,
     "start_time": "2025-12-05T21:23:22.827098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Model\n",
    "# -------------------------\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Dropout2d(0.2)\n",
    "        )\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.35),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = MyCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Train + Evaluate\n",
    "# -------------------------\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Run training\n",
    "# -------------------------\n",
    "for epoch in range(1, 31):\n",
    "    train_loss = train_one_epoch()\n",
    "    val_acc = evaluate(val_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch:2d} | Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Test accuracy\n",
    "# -------------------------\n",
    "test_acc = evaluate(test_loader)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b56e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T21:23:22.880215Z",
     "iopub.status.busy": "2025-12-05T21:23:22.879883Z",
     "iopub.status.idle": "2025-12-05T21:23:22.884964Z",
     "shell.execute_reply": "2025-12-05T21:23:22.883642Z"
    },
    "id": "ktKgGGaO7U65",
    "papermill": {
     "duration": 0.022133,
     "end_time": "2025-12-05T21:23:22.886378",
     "exception": false,
     "start_time": "2025-12-05T21:23:22.864245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize training and validation performance\n",
    "f, ax = plt.subplots(2, 1, figsize=(4, 5))\n",
    "\n",
    "# Plot training loss\n",
    "ax[0].plot(train_losses, color='b', label='Training Loss')\n",
    "ax[0].set_title(\"Training Loss\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot validation accuracy\n",
    "ax[1].plot(val_accuracies, color='r', label='Validation Accuracy')\n",
    "ax[1].set_title(\"Validation Accuracy\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a27924",
   "metadata": {
    "id": "CHYK7nZG7U65",
    "papermill": {
     "duration": 0.013302,
     "end_time": "2025-12-05T21:23:22.913593",
     "exception": false,
     "start_time": "2025-12-05T21:23:22.900291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. Second network: Build, train, and test another deep neural network, with an architecture of your choice, but at most 4M (four million) parameters, ensuring the architecture meets this constraint by verifying with model.summary()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4895f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# My model resnet\n",
    "# -------------------------\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.fc(x)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, dropout=0.35):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()\n",
    "        self.se = SEBlock(out_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.se(out)\n",
    "        return F.relu(out + self.shortcut(x))\n",
    "\n",
    "\n",
    "class BetterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # keep original width\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResBlock(64, 128),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResBlock(128, 256),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # add one extra block here (cheap)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            ResBlock(256, 278),\n",
    "            ResBlock(278, 278)\n",
    "        )\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(278, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "model = BetterCNN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe06754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Count Trainable Parameters\n",
    "# -------------------------\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "params = count_params(model)\n",
    "print(f\"\\nTotal Trainable Parameters: {params:,}  ({params/1e6:.3f}M)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# CIFAR-10 normalization constants\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "# -------------------------\n",
    "# Training Transformations\n",
    "# -------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.RandomGrayscale(p=0.07),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.15), ratio=(0.3, 3.3), value=0, inplace=False)\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# Validation/Test Transformations\n",
    "# -------------------------\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# Convert EXISTING NumPy arrays → torch dataset using transforms\n",
    "# -------------------------\n",
    "\n",
    "class NumpyCIFAR(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = int(self.labels[idx])\n",
    "        \n",
    "        # convert from NumPy (H,W,C) → PIL Image for transforms\n",
    "        img = transforms.ToPILImage()(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# create datasets with transforms\n",
    "train_dataset = NumpyCIFAR(X_train, y_train, transform=train_transform)\n",
    "val_dataset   = NumpyCIFAR(X_val,   y_val,   transform=val_transform)\n",
    "test_dataset  = NumpyCIFAR(X_test,  y_test,  transform=val_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=256, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders with augmentation are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming optim and device are defined elsewhere\n",
    "import torch.optim as optim \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# MODIFICATION: Added weight_decay (L2 regularization)\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.2,\n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max = 50,\n",
    "    eta_min = 1e-6 \n",
    ")\n",
    "\n",
    "# Setup for Gradient Clipping\n",
    "MAX_NORM = 10.0 \n",
    "\n",
    "# Early stopping\n",
    "best_val_acc = 0\n",
    "patience = 10 \n",
    "wait = 0\n",
    "\n",
    "train_losses = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f333604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # >>> MODIFICATION: Gradient Clipping\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=MAX_NORM)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd45dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Train (with checkpoint saving)\n",
    "# -------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "# Make sure checkpoint folder exists\n",
    "os.makedirs(\"checkpoints2\", exist_ok=True)\n",
    "BEST_MODEL_PATH = \"checkpoints2/best_model.pt\"\n",
    "\n",
    "for epoch in range(1, 501):\n",
    "\n",
    "    train_loss = train_one_epoch()\n",
    "    val_acc = evaluate(val_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # EARLY STOP & SAVE BEST CHECKPOINT\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        wait = 0\n",
    "        best_state = model.state_dict()  # keep copy in RAM\n",
    "        \n",
    "        # --- SAVE TO DISK (important if session dies) ---\n",
    "        torch.save(best_state, BEST_MODEL_PATH)\n",
    "        print(f\"  ➤ New best model saved at epoch {epoch} (val_acc={val_acc:.4f})\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"\\nEarly stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Load best model (whether early stopped or completed)\n",
    "model.load_state_dict(best_state)\n",
    "print(\"\\nBest validation accuracy:\", best_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ad4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Test Evaluation (loads best saved model)\n",
    "# -------------------------\n",
    "\n",
    "# Load best checkpoint from disk (safe even after crash)\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "    print(\"Loaded best saved checkpoint for testing.\")\n",
    "else:\n",
    "    print(\"Warning: No saved checkpoint found. Using current model state.\")\n",
    "\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "test_loss_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        test_loss_total += loss.item() * x.size(0)\n",
    "\n",
    "        _, preds = out.max(1)\n",
    "        test_correct += preds.eq(y).sum().item()\n",
    "        test_total += y.size(0)\n",
    "\n",
    "test_loss = test_loss_total / test_total\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(\"\\n====================\")\n",
    "print(\"TEST RESULTS\")\n",
    "print(\"====================\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, train_losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, val_accuracies)\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e14168",
   "metadata": {
    "id": "GVXGlx0o7U66",
    "papermill": {
     "duration": 0.018441,
     "end_time": "2025-12-05T23:52:14.325711",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.307270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "4. Modify the second network architecture by tuning the layer hyperparameters or adjusting the layer design to improve test accuracy while remaining within the four million parameter limit. Discuss your observations and the trade offs of the changes you make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d6961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:52:14.363862Z",
     "iopub.status.busy": "2025-12-05T23:52:14.363611Z",
     "iopub.status.idle": "2025-12-05T23:52:14.366498Z",
     "shell.execute_reply": "2025-12-05T23:52:14.365704Z"
    },
    "id": "9lE1pkmH7U66",
    "papermill": {
     "duration": 0.023171,
     "end_time": "2025-12-05T23:52:14.367149",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.343978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code goes here. Please make sure to explain the reasons behind your data processing and modeling choices.\n",
    "# 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ee5f8",
   "metadata": {
    "id": "qYhcGpgT7U66",
    "papermill": {
     "duration": 0.018405,
     "end_time": "2025-12-05T23:52:14.403916",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.385511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Open discussion questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3855c3b",
   "metadata": {
    "id": "BhKcal8l7U66",
    "papermill": {
     "duration": 0.018306,
     "end_time": "2025-12-05T23:52:14.440825",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.422519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. How did hyperparameter tuning (learning rate, dropout, batch size) affect your model’s accuracy? Were there any unexpected results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1606b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:52:14.478469Z",
     "iopub.status.busy": "2025-12-05T23:52:14.478239Z",
     "iopub.status.idle": "2025-12-05T23:52:14.480932Z",
     "shell.execute_reply": "2025-12-05T23:52:14.480226Z"
    },
    "id": "D5z2A3kI7U66",
    "papermill": {
     "duration": 0.022653,
     "end_time": "2025-12-05T23:52:14.481718",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.459065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
    "# 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d697b5",
   "metadata": {
    "id": "IR-1QiBU7U66",
    "papermill": {
     "duration": 0.018345,
     "end_time": "2025-12-05T23:52:14.518425",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.500080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. How did the constraint of keeping the model within 4 million parameters impact your design choices? Would a larger model necessarily perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b1b79a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:52:14.556147Z",
     "iopub.status.busy": "2025-12-05T23:52:14.555932Z",
     "iopub.status.idle": "2025-12-05T23:52:14.558575Z",
     "shell.execute_reply": "2025-12-05T23:52:14.557795Z"
    },
    "id": "QuiiZ4157U66",
    "papermill": {
     "duration": 0.022671,
     "end_time": "2025-12-05T23:52:14.559326",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.536655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
    "# 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244e65b",
   "metadata": {
    "id": "mr3nYv2_7U66",
    "papermill": {
     "duration": 0.018347,
     "end_time": "2025-12-05T23:52:14.596027",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.577680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. How can deep learning models trained on datasets like CIFAR-10 be applied in real-world scenarios? Give an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b81539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:52:14.634062Z",
     "iopub.status.busy": "2025-12-05T23:52:14.633849Z",
     "iopub.status.idle": "2025-12-05T23:52:14.636460Z",
     "shell.execute_reply": "2025-12-05T23:52:14.635726Z"
    },
    "id": "he9wMb2o7U66",
    "papermill": {
     "duration": 0.02268,
     "end_time": "2025-12-05T23:52:14.637193",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.614513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
    "# 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708303ec",
   "metadata": {
    "id": "2NcTFag07U66",
    "papermill": {
     "duration": 0.01803,
     "end_time": "2025-12-05T23:52:14.673636",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.655606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "4. Deep learning models for image recognition can have biases. What ethical concerns should be considered when deploying such models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc8e4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:52:14.711835Z",
     "iopub.status.busy": "2025-12-05T23:52:14.711615Z",
     "iopub.status.idle": "2025-12-05T23:52:14.714209Z",
     "shell.execute_reply": "2025-12-05T23:52:14.713489Z"
    },
    "id": "sGukYdCu7U66",
    "papermill": {
     "duration": 0.023059,
     "end_time": "2025-12-05T23:52:14.715230",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.692171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
    "# 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c116ea78",
   "metadata": {
    "id": "xueUV-Vh7U66",
    "papermill": {
     "duration": 0.018689,
     "end_time": "2025-12-05T23:52:14.752622",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.733933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "5. What was the most interesting or challenging part of this assignment? If you had more time, what additional improvements would you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a895a974",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T23:52:14.791672Z",
     "iopub.status.busy": "2025-12-05T23:52:14.791456Z",
     "iopub.status.idle": "2025-12-05T23:52:14.794034Z",
     "shell.execute_reply": "2025-12-05T23:52:14.793338Z"
    },
    "id": "IX_JXUJr7U66",
    "papermill": {
     "duration": 0.023085,
     "end_time": "2025-12-05T23:52:14.794786",
     "exception": false,
     "start_time": "2025-12-05T23:52:14.771701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your argument goes here. Please include data visualization and analysis to back up your argument.\n",
    "# 2.5"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8947.961005,
   "end_time": "2025-12-05T23:52:17.772375",
   "environment_variables": {},
   "exception": null,
   "input_path": "220205-assignment5-notebook-densenet-gpu.ipynb",
   "output_path": "220205-assignment5-notebook-densenet-gpu-output.ipynb",
   "parameters": {},
   "start_time": "2025-12-05T21:23:09.811370",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "31f1bdacb1674e3181e931cae861a6f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_569d163fdc8b4559b874f051d7c42e52",
      "max": 704,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fffc1186ce1c467389a80b5f46369b05",
      "value": 29
     }
    },
    "569d163fdc8b4559b874f051d7c42e52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6196efa8425d4791975591e383206c56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "722088ec7bf2491eb11c8330f5739347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6196efa8425d4791975591e383206c56",
      "placeholder": "​",
      "style": "IPY_MODEL_871857ecc6d94492a2acfb92440e2398",
      "value": "  4%"
     }
    },
    "871857ecc6d94492a2acfb92440e2398": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "970c3bea350549a4a32e01385c021391": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e576b24e23344a29679c22e515fd975": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6a608ac4a01463ea9bd0267d24686dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_722088ec7bf2491eb11c8330f5739347",
       "IPY_MODEL_31f1bdacb1674e3181e931cae861a6f4",
       "IPY_MODEL_b225f6f389bd4073b8c66ec5ca4e8aac"
      ],
      "layout": "IPY_MODEL_9e576b24e23344a29679c22e515fd975"
     }
    },
    "b225f6f389bd4073b8c66ec5ca4e8aac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_970c3bea350549a4a32e01385c021391",
      "placeholder": "​",
      "style": "IPY_MODEL_bc7c41e403bc46b486a45c0ffa5d626b",
      "value": " 29/704 [08:45&lt;3:19:38, 17.75s/it]"
     }
    },
    "bc7c41e403bc46b486a45c0ffa5d626b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fffc1186ce1c467389a80b5f46369b05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
