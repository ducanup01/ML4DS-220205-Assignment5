{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec533c2",
   "metadata": {
    "id": "Y6DyphAUEBOi",
    "papermill": {
     "duration": 0.007229,
     "end_time": "2025-12-08T19:54:04.010450",
     "exception": false,
     "start_time": "2025-12-08T19:54:04.003221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Assignment 5: Deep Learning {-}\n",
    "\n",
    "This assignment aims at familiarizing you with training and testing a Deep Neural Network (DNN). The dataset you will be working on is CIFAR-10. You will have to do:\n",
    "\n",
    "1.  **(5 points) Coding tasks:** The following questions involve writing code to complete specific tasks.  \n",
    "    1.1 *(1 point)* Load the CIFAR-10 dataset, visualize sample images, and perform data normalization to improve training performance.  \n",
    "    1.2 *(1 point)* First network: Build, train, and test a deep neural network with at least three convolutional layers, two fully connected layers, and two pooling layers.  \n",
    "    1.3 *(1 point)* Second network: Build, train, and test another deep neural network, with an architecture of your choice, but at most 4M (four million) parameters, ensuring the architecture meets this constraint by verifying with model.summary().  \n",
    "    1.4 *(2 points)* Modify the second network architecture by tuning the layer hyperparameters or adjusting the layer design to improve test accuracy while remaining within the four million parameter limit. Discuss your observations and the trade offs of the changes you make.  \n",
    "\n",
    "2.  **(5 points) Open discussion questions:** These discussion questions ask you to analyze and argue your points.  Feel free to include relevant code examples to strengthen your arguments.  \n",
    "    2.1 *(1 point)* How did hyperparameter tuning (learning rate, dropout, batch size) affect your model’s accuracy? Were there any unexpected results?  \n",
    "    2.2 *(1 point)* How did the constraint of keeping the model within 4 million parameters impact your design choices? Would a larger model necessarily perform better?  \n",
    "    2.3 *(1 point)* How can deep learning models trained on datasets like CIFAR-10 be applied in real-world scenarios? Give an example.  \n",
    "    2.4 *(1 point)* Deep learning models for image recognition can have biases. What ethical concerns should be considered when deploying such models?  \n",
    "    2.5 *(1 point)* What was the most interesting or challenging part of this assignment? If you had more time, what additional improvements would you make?  \n",
    "\n",
    "The dataset you will be working on is CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html) which consists of 60,000 32x32 colour images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. Here follows the ten object classes:\n",
    "* airplane\n",
    "*\tautomobile\n",
    "*\tbird\n",
    "*\tcat\n",
    "*\tdeer\n",
    "*\tdog\n",
    "*\tfrog\n",
    "*\thorse\n",
    "*\tship\n",
    "*\ttruck\n",
    "\n",
    "Here follows some data samples in the dataset:\n",
    "\n",
    "![alt text](https://docs.pytorch.org/tutorials/_images/cifar10.png)\n",
    "\n",
    "### Submission {-}\n",
    "The structure of submission folder should be organized as follows:\n",
    "\n",
    "- ./\\<StudentID>-assignment5-notebook.ipynb: Jupyter notebook containing source code.\n",
    "- ./\\<Test-accuracy>-\\<StudentID>.txt: accuracy of the second network on the test set (for extra credit, see the 'Evaluation' part below). For example if you get 0.8124 accuracy, the name of this file is 08124-2012345.txt. The file content is left empty.\n",
    "\n",
    "The submission folder is named ML4DS-\\<StudentID>-Assignment5 (e.g., ML4DS-2012345-Assigment5) and then compressed with the same name.\n",
    "    \n",
    "### Evaluation {-}\n",
    "Assignment evaluation will be conducted on how you accomplish the assignment requirements. It is a plus if you have modeling steps other than the basic requirements and achieve an excellent model accuracy. In addition, your code should conform to a Python coding convention such as PEP-8.\n",
    "\n",
    "EXTRA CREDIT: Top-3 submissions achieving the highest test accuracy on the second network (of 4M params at most) will be rewarded an extra credit. **You have to ensure the architecture meets this constraint by verifying and printing out the number of parameters with model.summary(). Please follow the submission format to be eligible for this extra credit.**\n",
    "\n",
    "### Deadline {-}\n",
    "Please visit Canvas for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16818fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:54:04.024623Z",
     "iopub.status.busy": "2025-12-08T19:54:04.024205Z",
     "iopub.status.idle": "2025-12-08T19:54:09.228282Z",
     "shell.execute_reply": "2025-12-08T19:54:09.226948Z"
    },
    "id": "o7yiMO-bEBOl",
    "papermill": {
     "duration": 5.212484,
     "end_time": "2025-12-08T19:54:09.229228",
     "exception": false,
     "start_time": "2025-12-08T19:54:04.016744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras              # Keras is the high-level API of TensorFlow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae6779c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:54:09.244088Z",
     "iopub.status.busy": "2025-12-08T19:54:09.243612Z",
     "iopub.status.idle": "2025-12-08T19:54:09.383107Z",
     "shell.execute_reply": "2025-12-08T19:54:09.382062Z"
    },
    "papermill": {
     "duration": 0.148362,
     "end_time": "2025-12-08T19:54:09.384395",
     "exception": false,
     "start_time": "2025-12-08T19:54:09.236033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6e7aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:54:09.399333Z",
     "iopub.status.busy": "2025-12-08T19:54:09.398928Z",
     "iopub.status.idle": "2025-12-08T19:54:11.675932Z",
     "shell.execute_reply": "2025-12-08T19:54:11.674736Z"
    },
    "id": "M6_ZhoDnfROl",
    "papermill": {
     "duration": 2.286456,
     "end_time": "2025-12-08T19:54:11.677528",
     "exception": false,
     "start_time": "2025-12-08T19:54:09.391072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT CHANGE THIS CODE\n",
    "\n",
    "# Load the cifar10 dataset and split train/test\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Split train/valid from the training set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=5)\n",
    "\n",
    "y_train = y_train.reshape(-1,)\n",
    "y_val = y_val.reshape(-1,)\n",
    "y_test = y_test.reshape(-1,)\n",
    "\n",
    "\n",
    "print(\"Train shape: X_train = \" + str(X_train.shape) + \", y_train = \" + str(y_train.shape))\n",
    "print(\"Validation shape: X_val = \" + str(X_val.shape) + \", y_val = \" + str(y_val.shape))\n",
    "print(\"Test shape: X_test = \" + str(X_test.shape) + \", y_test = \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46193238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:54:11.691878Z",
     "iopub.status.busy": "2025-12-08T19:54:11.691616Z",
     "iopub.status.idle": "2025-12-08T19:54:11.890920Z",
     "shell.execute_reply": "2025-12-08T19:54:11.889771Z"
    },
    "id": "v9EqVmHqfoL9",
    "papermill": {
     "duration": 0.20768,
     "end_time": "2025-12-08T19:54:11.891762",
     "exception": false,
     "start_time": "2025-12-08T19:54:11.684082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show some samples in the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "imgplot = plt.imshow(X_train[44999])\n",
    "plt.show()\n",
    "imgplot = plt.imshow(X_test[4999])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398267cc",
   "metadata": {
    "id": "OH7QNspP7U64",
    "papermill": {
     "duration": 0.006934,
     "end_time": "2025-12-08T19:54:11.905970",
     "exception": false,
     "start_time": "2025-12-08T19:54:11.899036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Coding tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7d9ef",
   "metadata": {
    "id": "NMvWeE2K7U64",
    "papermill": {
     "duration": 0.006394,
     "end_time": "2025-12-08T19:54:11.918840",
     "exception": false,
     "start_time": "2025-12-08T19:54:11.912446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Load the CIFAR-10 dataset, visualize sample images, and perform data normalization to improve training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81daa13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:54:11.933406Z",
     "iopub.status.busy": "2025-12-08T19:54:11.933138Z",
     "iopub.status.idle": "2025-12-08T19:54:12.366086Z",
     "shell.execute_reply": "2025-12-08T19:54:12.365043Z"
    },
    "id": "oBUR3PfK7U64",
    "papermill": {
     "duration": 0.445124,
     "end_time": "2025-12-08T19:54:12.370345",
     "exception": false,
     "start_time": "2025-12-08T19:54:11.925221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "# Count how many samples belong to each class\n",
    "class_counts = np.bincount(y_train.flatten(), minlength=10)\n",
    "\n",
    "# For each class, collect indices of all images\n",
    "class_indices = {i: np.where(y_train.flatten() == i)[0] for i in range(10)}\n",
    "\n",
    "# Plot setup\n",
    "fig, axes = plt.subplots(4, 3, figsize=(6, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Randomly pick 4 images from this class\n",
    "    idxs = np.random.choice(class_indices[i], 4, replace=False)\n",
    "    imgs = X_train[idxs]\n",
    "\n",
    "    # Create a small 2x2 grid inside the subplot\n",
    "    combined = np.zeros((64, 64, 3), dtype=np.uint8)  # 32*2 = 64 pixels per side\n",
    "    combined[:32, :32] = imgs[0]\n",
    "    combined[:32, 32:] = imgs[1]\n",
    "    combined[32:, :32] = imgs[2]\n",
    "    combined[32:, 32:] = imgs[3]\n",
    "\n",
    "    ax.imshow(combined)\n",
    "    ax.set_title(f\"{class_names[i]} ({class_counts[i]})\", fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Turn off remaining unused subplots\n",
    "for ax in axes[10:]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2be59c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:54:12.399709Z",
     "iopub.status.busy": "2025-12-08T19:54:12.399426Z",
     "iopub.status.idle": "2025-12-08T19:54:13.005951Z",
     "shell.execute_reply": "2025-12-08T19:54:13.004542Z"
    },
    "id": "Lattfopb7U65",
    "papermill": {
     "duration": 0.621967,
     "end_time": "2025-12-08T19:54:13.006778",
     "exception": false,
     "start_time": "2025-12-08T19:54:12.384811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert pixel values from 0–255 to 0–1 (normalizing)\n",
    "X_train_norm = X_train.astype(\"float32\") / 255.0\n",
    "X_val_norm = X_val.astype(\"float32\") / 255.0\n",
    "X_test_norm = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "print(\"Data normalized: pixel values are now between 0 and 1.\")\n",
    "print(\"Random normalized pixel: \", X_train_norm[44998][16][16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20986b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:54:13.036453Z",
     "iopub.status.busy": "2025-12-08T19:54:13.036116Z",
     "iopub.status.idle": "2025-12-08T19:54:13.115747Z",
     "shell.execute_reply": "2025-12-08T19:54:13.114295Z"
    },
    "papermill": {
     "duration": 0.095876,
     "end_time": "2025-12-08T19:54:13.116688",
     "exception": false,
     "start_time": "2025-12-08T19:54:13.020812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Training on:\", device)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_t = torch.tensor(X_train_norm, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "X_val_t   = torch.tensor(X_val_norm, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "X_test_t  = torch.tensor(X_test_norm, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "\n",
    "y_train_t = torch.tensor(y_train.reshape(-1), dtype=torch.long)\n",
    "y_val_t   = torch.tensor(y_val.reshape(-1), dtype=torch.long)\n",
    "y_test_t  = torch.tensor(y_test.reshape(-1), dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=128)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b2b8fa",
   "metadata": {
    "id": "uPp7-Tum7U65",
    "papermill": {
     "duration": 0.013594,
     "end_time": "2025-12-08T19:54:13.144339",
     "exception": false,
     "start_time": "2025-12-08T19:54:13.130745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. First network: Build, train, and test a deep neural network with at least three convolutional layers, two fully connected layers, and two pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b699c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:54:13.173896Z",
     "iopub.status.busy": "2025-12-08T19:54:13.173451Z",
     "iopub.status.idle": "2025-12-08T19:57:10.104939Z",
     "shell.execute_reply": "2025-12-08T19:57:10.103354Z"
    },
    "id": "xgMj8cID7U65",
    "papermill": {
     "duration": 176.948182,
     "end_time": "2025-12-08T19:57:10.105941",
     "exception": false,
     "start_time": "2025-12-08T19:54:13.157759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Model\n",
    "# -------------------------\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Dropout2d(0.2)\n",
    "        )\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.35),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = MyCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Train + Evaluate\n",
    "# -------------------------\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Run training\n",
    "# -------------------------\n",
    "for epoch in range(1, 31):\n",
    "    train_loss = train_one_epoch()\n",
    "    val_acc = evaluate(val_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch:2d} | Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Test accuracy\n",
    "# -------------------------\n",
    "test_acc = evaluate(test_loader)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b56e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:57:10.139574Z",
     "iopub.status.busy": "2025-12-08T19:57:10.138768Z",
     "iopub.status.idle": "2025-12-08T19:57:10.403915Z",
     "shell.execute_reply": "2025-12-08T19:57:10.402697Z"
    },
    "id": "ktKgGGaO7U65",
    "papermill": {
     "duration": 0.282706,
     "end_time": "2025-12-08T19:57:10.404795",
     "exception": false,
     "start_time": "2025-12-08T19:57:10.122089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize training and validation performance\n",
    "f, ax = plt.subplots(2, 1, figsize=(4, 5))\n",
    "\n",
    "# Plot training loss\n",
    "ax[0].plot(train_losses, color='b', label='Training Loss')\n",
    "ax[0].set_title(\"Training Loss\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot validation accuracy\n",
    "ax[1].plot(val_accuracies, color='r', label='Validation Accuracy')\n",
    "ax[1].set_title(\"Validation Accuracy\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a27924",
   "metadata": {
    "id": "CHYK7nZG7U65",
    "papermill": {
     "duration": 0.015153,
     "end_time": "2025-12-08T19:57:10.437381",
     "exception": false,
     "start_time": "2025-12-08T19:57:10.422228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. Second network: Build, train, and test another deep neural network, with an architecture of your choice, but at most 4M (four million) parameters, ensuring the architecture meets this constraint by verifying with model.summary()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4895f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:57:10.469041Z",
     "iopub.status.busy": "2025-12-08T19:57:10.468673Z",
     "iopub.status.idle": "2025-12-08T19:57:10.524079Z",
     "shell.execute_reply": "2025-12-08T19:57:10.522689Z"
    },
    "papermill": {
     "duration": 0.072803,
     "end_time": "2025-12-08T19:57:10.524979",
     "exception": false,
     "start_time": "2025-12-08T19:57:10.452176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# My model resnet\n",
    "# -------------------------\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.fc(x)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()\n",
    "        self.se = SEBlock(out_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.se(out)\n",
    "        return F.relu(out + self.shortcut(x))\n",
    "\n",
    "\n",
    "class BetterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # keep original width\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResBlock(64, 128),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResBlock(128, 256),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            ResBlock(256, 278),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            ResBlock(278, 278)\n",
    "        )\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(278, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "model = BetterCNN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c2d010",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:57:10.558456Z",
     "iopub.status.busy": "2025-12-08T19:57:10.558128Z",
     "iopub.status.idle": "2025-12-08T19:57:10.563792Z",
     "shell.execute_reply": "2025-12-08T19:57:10.562471Z"
    },
    "papermill": {
     "duration": 0.023284,
     "end_time": "2025-12-08T19:57:10.564527",
     "exception": false,
     "start_time": "2025-12-08T19:57:10.541243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Count Trainable Parameters\n",
    "# -------------------------\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "params = count_params(model)\n",
    "print(f\"\\nTotal Trainable Parameters: {params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7dcfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:57:10.596044Z",
     "iopub.status.busy": "2025-12-08T19:57:10.595755Z",
     "iopub.status.idle": "2025-12-08T19:57:10.729055Z",
     "shell.execute_reply": "2025-12-08T19:57:10.727814Z"
    },
    "papermill": {
     "duration": 0.150263,
     "end_time": "2025-12-08T19:57:10.729969",
     "exception": false,
     "start_time": "2025-12-08T19:57:10.579706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# CIFAR-10 normalization constants\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "# -------------------------\n",
    "# Training Transformations\n",
    "# -------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.RandomGrayscale(p=0.07),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "    transforms.RandomErasing(p=0.9, scale=(0.02, 0.15), ratio=(0.3, 3.3), value=0, inplace=False)\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# Validation/Test Transformations\n",
    "# -------------------------\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# Convert EXISTING NumPy arrays → torch dataset using transforms\n",
    "# -------------------------\n",
    "\n",
    "class NumpyCIFAR(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = int(self.labels[idx])\n",
    "        \n",
    "        # convert from NumPy (H,W,C) → PIL Image for transforms\n",
    "        img = transforms.ToPILImage()(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# create datasets with transforms\n",
    "train_dataset = NumpyCIFAR(X_train, y_train, transform=train_transform)\n",
    "val_dataset   = NumpyCIFAR(X_val,   y_val,   transform=val_transform)\n",
    "test_dataset  = NumpyCIFAR(X_test,  y_test,  transform=val_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=256, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders with augmentation are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c7a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:57:10.764138Z",
     "iopub.status.busy": "2025-12-08T19:57:10.763844Z",
     "iopub.status.idle": "2025-12-08T19:57:10.769567Z",
     "shell.execute_reply": "2025-12-08T19:57:10.768379Z"
    },
    "papermill": {
     "duration": 0.023635,
     "end_time": "2025-12-08T19:57:10.770306",
     "exception": false,
     "start_time": "2025-12-08T19:57:10.746671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Label Smoothing Cross Entropy\n",
    "# -------------------------\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        assert 0.0 <= smoothing < 1.0\n",
    "        self.s = smoothing\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        n_classes = logits.size(-1)\n",
    "\n",
    "        # log probabilities\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        # create smoothed targets\n",
    "        with torch.no_grad():\n",
    "            true = torch.zeros_like(log_probs)\n",
    "            true.fill_(self.s / (n_classes - 1))\n",
    "            true.scatter_(1, target.unsqueeze(1), 1 - self.s)\n",
    "\n",
    "        return -(true * log_probs).sum(dim=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31a589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:57:10.802235Z",
     "iopub.status.busy": "2025-12-08T19:57:10.801951Z",
     "iopub.status.idle": "2025-12-08T19:57:10.808115Z",
     "shell.execute_reply": "2025-12-08T19:57:10.807004Z"
    },
    "papermill": {
     "duration": 0.023343,
     "end_time": "2025-12-08T19:57:10.808885",
     "exception": false,
     "start_time": "2025-12-08T19:57:10.785542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming optim and device are defined elsewhere\n",
    "import torch.optim as optim \n",
    "\n",
    "criterion = LabelSmoothingCrossEntropy(smoothing=0.05)\n",
    "\n",
    "# MODIFICATION: Added weight_decay (L2 regularization)\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.05,\n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4,\n",
    "    nesterov=True\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=0.96,\n",
    "    patience=2,\n",
    "    threshold=1e-4, \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Setup for Gradient Clipping\n",
    "MAX_NORM = 10.0\n",
    "\n",
    "# Early stopping\n",
    "best_val_acc = 0\n",
    "patience = 300\n",
    "wait = 0\n",
    "\n",
    "train_losses = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a0968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:57:10.840601Z",
     "iopub.status.busy": "2025-12-08T19:57:10.840289Z",
     "iopub.status.idle": "2025-12-08T19:57:10.847594Z",
     "shell.execute_reply": "2025-12-08T19:57:10.846599Z"
    },
    "papermill": {
     "duration": 0.02427,
     "end_time": "2025-12-08T19:57:10.848324",
     "exception": false,
     "start_time": "2025-12-08T19:57:10.824054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    \"\"\"\n",
    "    x: batch images (B,C,H,W)\n",
    "    y: batch labels (B,)\n",
    "    returns: mixed_x, y_a, y_b, lambda\n",
    "    \"\"\"\n",
    "\n",
    "    if alpha <= 0:\n",
    "        return x, y, y, 1.0\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    y_a = y\n",
    "    y_b = y[index]\n",
    "\n",
    "    # bounding box\n",
    "    _, _, H, W = x.size()\n",
    "    cut_w = int(W * np.sqrt(1 - lam))\n",
    "    cut_h = int(H * np.sqrt(1 - lam))\n",
    "\n",
    "    # random center\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    x1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    x2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    y1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    y2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    # apply patch\n",
    "    x[:, :, y1:y2, x1:x2] = x[index][:, :, y1:y2, x1:x2]\n",
    "\n",
    "    lam = 1 - ((x2 - x1) * (y2 - y1)) / (W * H)\n",
    "\n",
    "    return x, y_a, y_b, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f333604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:57:10.880396Z",
     "iopub.status.busy": "2025-12-08T19:57:10.880095Z",
     "iopub.status.idle": "2025-12-08T19:57:10.886671Z",
     "shell.execute_reply": "2025-12-08T19:57:10.885511Z"
    },
    "papermill": {
     "duration": 0.023743,
     "end_time": "2025-12-08T19:57:10.887370",
     "exception": false,
     "start_time": "2025-12-08T19:57:10.863627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # apply cutmix\n",
    "        X_cut, y_a, y_b, lam = cutmix_data(X, y, alpha=1.0)\n",
    "\n",
    "        # forward\n",
    "        out = model(X_cut)\n",
    "\n",
    "        # compute mixed loss\n",
    "        loss = lam * criterion(out, y_a) + (1 - lam) * criterion(out, y_b)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # >>> MODIFICATION: Gradient Clipping\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=MAX_NORM)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd45dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T19:57:10.919050Z",
     "iopub.status.busy": "2025-12-08T19:57:10.918790Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-12-08T19:57:10.902554",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# -------------------------\n",
    "# Setup\n",
    "# -------------------------\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "BEST_MODEL_PATH = \"checkpoints/best_test_model.pt\"\n",
    "METRICS_PATH = \"checkpoints/metrics.pt\"\n",
    "\n",
    "best_test_acc = 0.0\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "lrs = []\n",
    "\n",
    "wait = 0  # for early stopping\n",
    "best_state = None\n",
    "\n",
    "# -------------------------\n",
    "# Helper: compute accuracy\n",
    "# -------------------------\n",
    "def compute_accuracy(model, loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            _, preds = out.max(1)\n",
    "            correct += preds.eq(y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Training Loop\n",
    "# -------------------------\n",
    "for epoch in range(1, 1001):\n",
    "\n",
    "    # Train one epoch\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        _, preds = out.max(1)\n",
    "        running_correct += preds.eq(y).sum().item()\n",
    "        running_total += y.size(0)\n",
    "\n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc = running_correct / running_total\n",
    "\n",
    "    # Validation accuracy\n",
    "    val_acc = compute_accuracy(model, val_loader)\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step(val_acc)\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    # Test accuracy at this epoch\n",
    "    test_acc = compute_accuracy(model, test_loader)\n",
    "\n",
    "    # Save metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    lrs.append(current_lr)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | LR={current_lr:.6f} | Loss={train_loss:.4f} | \"\n",
    "      f\"Train Acc={train_acc:.4f} | Val Acc={val_acc:.4f} | Test Acc={test_acc:.4f}\")\n",
    "\n",
    "\n",
    "    # Save best TEST accuracy checkpoint\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_state = model.state_dict()\n",
    "        torch.save(best_state, BEST_MODEL_PATH)\n",
    "        print(f\"  ➤ Saved new best TEST model (test_acc={test_acc:.4f})\")\n",
    "\n",
    "    # -------------------------\n",
    "    # SAVE METRICS EVERY EPOCH\n",
    "    # -------------------------\n",
    "    torch.save({\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_accuracies\": train_accuracies,\n",
    "        \"val_accuracies\": val_accuracies,\n",
    "        \"test_accuracies\": test_accuracies,\n",
    "        \"lrs\": lrs\n",
    "    }, METRICS_PATH)\n",
    "\n",
    "    # Optional early stopping\n",
    "    if val_acc <= val_accuracies[-1] and epoch > 1:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    else:\n",
    "        wait = 0\n",
    "\n",
    "print(\"\\nTraining complete. Best TEST accuracy =\", best_test_acc)\n",
    "print(\"Saved metrics to:\", METRICS_PATH)\n",
    "print(\"Saved best model to:\", BEST_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25f533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T13:48:43.828721Z",
     "iopub.status.busy": "2025-12-07T13:48:43.828454Z",
     "iopub.status.idle": "2025-12-07T13:48:44.080364Z",
     "shell.execute_reply": "2025-12-07T13:48:44.079616Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "METRICS_PATH = \"checkpoints/metrics.pt\"\n",
    "\n",
    "data = torch.load(METRICS_PATH)\n",
    "\n",
    "train_losses = data[\"train_losses\"]\n",
    "train_accuracies = data[\"train_accuracies\"]\n",
    "val_accuracies = data[\"val_accuracies\"]\n",
    "test_accuracies = data[\"test_accuracies\"]\n",
    "lrs = data[\"lrs\"]\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(epochs, train_losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(epochs, train_accuracies, label=\"Train\")\n",
    "plt.plot(epochs, val_accuracies, label=\"Validation\")\n",
    "plt.plot(epochs, test_accuracies, label=\"Test\")\n",
    "plt.title(\"Accuracies\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(epochs, lrs)\n",
    "plt.title(\"Learning Rate\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"LR\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e14168",
   "metadata": {
    "id": "GVXGlx0o7U66",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "4. Modify the second network architecture by tuning the layer hyperparameters or adjusting the layer design to improve test accuracy while remaining within the four million parameter limit. Discuss your observations and the trade offs of the changes you make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa886240",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "There are 3 types of modifications I have done to the model:\n",
    "- Adjusting layer design\n",
    "- Tuning layer hyperparameters\n",
    "- Preprocessing input data\n",
    "1. Adjusting layer design\n",
    "I used a model that is similar to ResNet instead of traditional CNN to avoid gradient vanish. There are 3 stages of Residual Block, I find that to be a sweet spot because 2 has lower accuracy and 4 takes longer computational time. Within each block, I use 2 blocks of Conv -> ReLU -> BatchNorm -> Squeeze-Excitation block.\n",
    "2. I intended to do the traditional 64 -> 128 -> 256 -> 512 filters for each subsequent block, but 512 at last layer has too many hyperparameters so I tuned it down to 278 which has slightly lower than 4M params.\n",
    "3. For preprocessing, I used data augmentation, and a few more techniques to make the model less prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ee5f8",
   "metadata": {
    "id": "qYhcGpgT7U66",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 2. Open discussion questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3855c3b",
   "metadata": {
    "id": "BhKcal8l7U66",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "1. How did hyperparameter tuning (learning rate, dropout, batch size) affect your model’s accuracy? Were there any unexpected results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526e720",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- For my model, I used a relatively high learning rate, and then used a Cosine Annealing LR scheduler to decrease it overtime. So it doesn't matter too much what the initial LR is. At the last quarter of the training process it tends to be at a sweet spot that the model learns the minor details the fastest.\n",
    "- Dropout 0.05 or 0.45 has only a 0.5% difference in result.\n",
    "- Batch size being 512 makes the CUDA ran out of memory (I think), so I decreased back to 256 and it ran normally.\n",
    "- Number of epoch also doesn't affect the end results beyond certain point, as I used Cosine Annealing LR. So 50 or 200 yielded the same result.\n",
    "- Converntionally, number of filters should be a multiple of 2. I used an odd multiplier like 1.4 and the model did significantly worse.\n",
    "- And the most unexpected thing is label smoothing. I used it instead of Cross Entropy Loss function, and while it gave the same test accuracy at ~93-94%, the loss is much higher (0.5 instead of 0.01)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d697b5",
   "metadata": {
    "id": "IR-1QiBU7U66",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "2. How did the constraint of keeping the model within 4 million parameters impact your design choices? Would a larger model necessarily perform better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70340843",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- As my model has a handicap layer of 278 filters, I believe that is the main reason why it couldn't perform better.\n",
    "- A larger model does not necessarily mean it can perform better. There are also other factors such as image preprocessing, if the user does not perform correctly, it can lead to the model perform no better than random chance. (For example I once accidentally set all pixels to 0-1 instead of normalizing, making the whole training set black. The model then has 10% accuracy which is basically random guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244e65b",
   "metadata": {
    "id": "mr3nYv2_7U66",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "3. How can deep learning models trained on datasets like CIFAR-10 be applied in real-world scenarios? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327844d4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- CIFAR-10 is not a good dataset for real world applications. There are better ones such as ImageNet or DINOv2, however this is a good starting point for AI students. It can be used in low-resolution camera for detecting objects in a student project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708303ec",
   "metadata": {
    "id": "2NcTFag07U66",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "4. Deep learning models for image recognition can have biases. What ethical concerns should be considered when deploying such models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf5096",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Surely bias training data leads to bias in predictions, and no dataset can perfectly represents the real world. There will be concerns about interpretability, privacy, responsibility, etc\n",
    "- Interpretability: when a model makes certain prediction and cannot justify it, people tend to not believe it as much\n",
    "- Privacy: data collection of images that were not supposed to be taken can be a debatable topic.\n",
    "- Responsibilty: AI cannot go to jail, therefore someone might have to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c116ea78",
   "metadata": {
    "id": "xueUV-Vh7U66",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "5. What was the most interesting or challenging part of this assignment? If you had more time, what additional improvements would you make?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c9878",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- Playing this AI game is like gambling, I let the model run and expect good results, and when I come back to it, the dopamine rush when I see an unexpected results hit like a truck.\n",
    "Also this game is expensive, I need to have good GPUs to do enough trials and error so that I can learn something about it.\n",
    "- I've had enough time with it, but if I had more time, I will try other models like DenseNet or transformer. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "220205-assignment5-notebook.ipynb",
   "output_path": "220205-assignment5-notebook-output.ipynb",
   "parameters": {},
   "start_time": "2025-12-08T19:54:03.098883",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "31f1bdacb1674e3181e931cae861a6f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_569d163fdc8b4559b874f051d7c42e52",
      "max": 704,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fffc1186ce1c467389a80b5f46369b05",
      "value": 29
     }
    },
    "569d163fdc8b4559b874f051d7c42e52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6196efa8425d4791975591e383206c56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "722088ec7bf2491eb11c8330f5739347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6196efa8425d4791975591e383206c56",
      "placeholder": "​",
      "style": "IPY_MODEL_871857ecc6d94492a2acfb92440e2398",
      "value": "  4%"
     }
    },
    "871857ecc6d94492a2acfb92440e2398": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "970c3bea350549a4a32e01385c021391": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e576b24e23344a29679c22e515fd975": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6a608ac4a01463ea9bd0267d24686dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_722088ec7bf2491eb11c8330f5739347",
       "IPY_MODEL_31f1bdacb1674e3181e931cae861a6f4",
       "IPY_MODEL_b225f6f389bd4073b8c66ec5ca4e8aac"
      ],
      "layout": "IPY_MODEL_9e576b24e23344a29679c22e515fd975"
     }
    },
    "b225f6f389bd4073b8c66ec5ca4e8aac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_970c3bea350549a4a32e01385c021391",
      "placeholder": "​",
      "style": "IPY_MODEL_bc7c41e403bc46b486a45c0ffa5d626b",
      "value": " 29/704 [08:45&lt;3:19:38, 17.75s/it]"
     }
    },
    "bc7c41e403bc46b486a45c0ffa5d626b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fffc1186ce1c467389a80b5f46369b05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
